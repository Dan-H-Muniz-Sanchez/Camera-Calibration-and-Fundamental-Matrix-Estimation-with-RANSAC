{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SIFT_Matches(image1, image2, MAX_FEATURES=3000):\n",
    "    # Convertimos las imágenes de color a escala de grises\n",
    "    new_image_1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "    new_image_2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Creamos un detector SIFT con un límite máximo de características\n",
    "    sift = cv2.SIFT_create(MAX_FEATURES)\n",
    "\n",
    "    # Detectamos y calculamos descriptores para las características en ambas imágenes\n",
    "    Key_Points_1, des1 = sift.detectAndCompute(new_image_1, None)\n",
    "    Key_Points_2, des2 = sift.detectAndCompute(new_image_2, None)\n",
    "\n",
    "    # Utilizamos el matcher de fuerza bruta (Brute-Force) para hacer coincidir los descriptores\n",
    "    Bjf = cv2.BFMatcher()\n",
    "    matches = Bjf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    # Filtramos las coincidencias para mantener solo las que son lo suficientemente buenas\n",
    "    Correct_Matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            Correct_Matches.append([m])\n",
    "\n",
    "    # Extraemos las coordenadas de las características coincidentes en ambas imágenes\n",
    "    left_coords = np.float32([Key_Points_1[m[0].queryIdx].pt for m in Correct_Matches])\n",
    "    right_coords = np.float32([Key_Points_2[m[0].trainIdx].pt for m in Correct_Matches])\n",
    "\n",
    "    return left_coords, right_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread(\"MIT1.jpg\")\n",
    "image2 = cv2.imread(\"MIT2.jpg\")\n",
    "\n",
    "# Llamar a la función SIFT_Matches\n",
    "left_coords, right_coords = SIFT_Matches(image1, image2)\n",
    "\n",
    "# Dibujar puntos en las imágenes\n",
    "image1_points = image1.copy()\n",
    "image2_points = image2.copy()\n",
    "\n",
    "for coord in left_coords:\n",
    "    x, y = coord\n",
    "    cv2.circle(image1_points, (int(x), int(y)), 5, (0, 255, 0), -1)  # Dibuja un círculo verde en la imagen1\n",
    "\n",
    "for coord in right_coords:\n",
    "    x, y = coord\n",
    "    cv2.circle(image2_points, (int(x), int(y)), 5, (0, 255, 0), -1) \n",
    "\n",
    "# Mostrar las imágenes con los puntos dibujados\n",
    "cv2.imshow(\"Image 1 with Points\", image1_points)\n",
    "cv2.imshow(\"Image 2 with Points\", image2_points)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FUNDAMENTAL_MATRIX_ESTIMATION(LEFT_IMG_PTS, RIGHT_IMG_PTS):\n",
    "\n",
    "    A = [] \n",
    "\n",
    "    for i in range(8): #Iter over 7 random points\n",
    "        ul,vl = LEFT_IMG_PTS[i]\n",
    "        ur,vr = RIGHT_IMG_PTS[i]\n",
    "\n",
    "        row = np.asarray([ul * ur, ul * vr, ul, vl * ur, vr * vl, vl, ur, vr, 1])\n",
    "\n",
    "        A.append(row)\n",
    "\n",
    "    \n",
    "\n",
    "    A = np.asarray(A)\n",
    "\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = np.reshape(V[-1,:],(3,3))\n",
    "\n",
    "    UF , SF , VF = np.linalg.svd(F)\n",
    "    SF = np.diag(SF)\n",
    "    SF[2,2] = 0\n",
    "\n",
    "    F = UF @ (SF @ VF)\n",
    "\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.20230859e-07  9.21322929e-06 -5.81492367e-03]\n",
      " [-3.28734304e-07  8.23863406e-07 -3.21515119e-04]\n",
      " [ 6.92598728e-05 -1.52495909e-03  9.99981876e-01]]\n"
     ]
    }
   ],
   "source": [
    "F = FUNDAMENTAL_MATRIX_ESTIMATION(left_coords,right_coords)\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CENTERING DE DATA CORRESPONDENCE POINTS\n",
    "ul_mean = np.mean (left_coords[ : , 0])\n",
    "vl_mean = np.mean (left_coords[ : , 1])\n",
    "\n",
    "ur_mean = np.mean (right_coords[ : , 0])\n",
    "vr_mean = np.mean (right_coords[ : , 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_l = np.sqrt(2) / ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
